{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from itertools import chain\n",
    "\n",
    "def compare_approximate(first, second):\n",
    "    \"\"\"Return whether two dicts of arrays are roughly equal\"\"\"\n",
    "    if first.keys() != second.keys():\n",
    "        return False, 1\n",
    "        \n",
    "    return all(np.allclose(first[key], second[key], equal_nan=True) for key in first), 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/lorenzo/phd/NS_HOT_EOS/EOS/compOSE/FOP(SFHoY)'\n",
    "h5_name = 'TEST_' + PATH.split('/')[-1] + '.h5'\n",
    "OUTPUT = os.path.join(PATH, h5_name)\n",
    "files = [file for file in os.listdir(PATH) if 'eos.' in file and not '.pdf' in file and not '.init' in file]\n",
    "# files\n",
    "\n",
    "files = ['eos.nb', 'eos.thermo', 'eos.t', 'eos.yq', 'eos.compo']\n",
    "\n",
    "skip_rows = {\n",
    "                'eos.nb' : 2,\n",
    "                'eos.thermo' : 1,\n",
    "                'eos.t' : 2,\n",
    "                'eos.yq' : 2,\n",
    "                'eos.compo' : 0\n",
    "            }\n",
    "\n",
    "def custom_read(FILE_PATH):\n",
    "\n",
    "    with open(FILE_PATH, 'r') as f:\n",
    "        all_data=[x.split() for x in f.readlines()]\n",
    "\n",
    "    n_cols = max(len(line) for line in all_data)\n",
    "    n_rows = len(all_data)\n",
    "    out_arr = np.full((n_rows, n_cols), np.NaN)\n",
    "\n",
    "    for i, line in enumerate(all_data):\n",
    "        out_arr[i, :len(line)] = np.array(line, dtype = np.float64)\n",
    "    \n",
    "    return out_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {}\n",
    "for file in files:\n",
    "    FILE_PATH = os.path.join(PATH, file)\n",
    "    try:\n",
    "        data[file] = np.loadtxt(FILE_PATH, skiprows=skip_rows[file], dtype=np.float64)\n",
    "        if file == 'eos.thermo':\n",
    "            with open(FILE_PATH) as f:\n",
    "                m_n, m_p, _ = np.fromstring(f.readline().strip('\\n'), dtype = float, sep='\\t')\n",
    "    except ValueError:\n",
    "        data[file] = custom_read(FILE_PATH)\n",
    "    except KeyError:\n",
    "        print(f'{file} not found!')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gli indici sono da 1 a N in Fortran, da 0 a N-1 in Python\n",
    "index_T    = data['eos.thermo'][:, 0].astype(int) - 1\n",
    "index_nb   = data['eos.thermo'][:, 1].astype(int) - 1\n",
    "index_yq   = data['eos.thermo'][:, 2].astype(int) - 1\n",
    "\n",
    "logrho     = np.log10(data['eos.nb'] * m_n)  # log_10( nb * m_n ), nb exponential   MeV / fm^3\n",
    "pointsrho  = len(logrho)\n",
    "\n",
    "y_q        = data['eos.yq']                  # LINEARE                 Adimensionale\n",
    "pointsyq   = len(y_q)\n",
    "\n",
    "logtemp    = np.log10(data['eos.t'])         # log_10( T ), T exponential           MeV\n",
    "pointstemp = len(logtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from (i_T, i_nb, i_Ye) to 1D index\n",
    "def maps(i, j, k, pointsrho, pointsyq):\n",
    "    \"\"\"\n",
    "    Defines a function that maps indices from the original matrix to the reshaped matrix calculating the index in the original matrix corresponding to the given indices in the reshaped matrix.\n",
    "    \"\"\"\n",
    "    return i + pointsrho * pointsyq * j + pointsyq * k\n",
    "\n",
    " \n",
    "def reshape_array(original_matrix, pointsrho, pointstemp, pointsyq):\n",
    "    \"\"\"\n",
    "    Reshapes the original matrix into the desired shape using the maps function.\n",
    "    \"\"\"\n",
    "    indices = maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :], pointsrho, pointsyq)\n",
    "    # Returns the values from the original matrix at the calculated indices\n",
    "    return np.take(original_matrix, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE PRESSURE, RESHAPE AND TEST FOR EQUIVALENCE!!! Secondo metodo circa 28 volte più veloce del primo\n",
    "\n",
    "pressure   = data['eos.thermo'][:, 3] * data['eos.nb'][index_nb]   # MeV / fm^3\n",
    "pp = np.zeros((pointsyq, pointstemp, pointsrho))\n",
    "for i in range(pointsyq):\n",
    "    for j in range(pointstemp):\n",
    "        for k in range(pointsrho):\n",
    "            pp[i, j, k] = pressure[maps(i,j,k, pointsrho, pointsyq)]\n",
    "\n",
    "pressure_r = reshape_array(pressure, pointsrho, pointstemp, pointsyq)\n",
    "\n",
    "##### NEW\n",
    "pressure_shift = np.abs(np.min([np.min(pressure_r), 0])) * 1.01\n",
    "pressure_s = pressure_r + pressure_shift\n",
    "#####\n",
    "\n",
    "np.testing.assert_allclose(pressure_r, pp)\n",
    "\n",
    "#############################################\n",
    "## COMPUTE ENTROPY, RESHAPE AND TEST FOR EQUIVALENCE!!! Secondo metodo circa 28 volte più veloce del primo\n",
    "\n",
    "entropy    = data['eos.thermo'][:, 4] * data['eos.nb'][index_nb]   # Adimensionale\n",
    "ee = np.zeros((pointsyq, pointstemp, pointsrho))\n",
    "for i in range(pointsyq):\n",
    "    for j in range(pointstemp):\n",
    "        for k in range(pointsrho):\n",
    "            ee[i, j, k] = entropy[maps(i,j,k, pointsrho, pointsyq)]\n",
    "\n",
    "entropy_r = reshape_array(entropy, pointsrho, pointstemp, pointsyq)\n",
    "\n",
    "np.testing.assert_allclose(entropy_r, ee)\n",
    "\n",
    "#############################################\n",
    "## COMPUTE ENERGY, RESHAPE AND TEST FOR EQUIVALENCE!!! Secondo metodo circa 28 volte più veloce del primo\n",
    "# Se ho capito bene Q7 --> data['eos.thermo'][:, 9] è esattamente \"energy\" negli h5 (da capire come la scala)\n",
    "energy     = data['eos.thermo'][:, 9]\n",
    "en = np.zeros((pointsyq, pointstemp, pointsrho))\n",
    "for i in range(pointsyq):\n",
    "    for j in range(pointstemp):\n",
    "        for k in range(pointsrho):\n",
    "            en[i, j, k] = energy[maps(i,j,k, pointsrho, pointsyq)]\n",
    "\n",
    "energy_r = reshape_array(energy, pointsrho, pointstemp, pointsyq)\n",
    "\n",
    "energy_shift = np.abs(np.min([np.min(energy_r), 0])) * 1.01\n",
    "energy_s = energy_r + energy_shift\n",
    "\n",
    "np.testing.assert_allclose(energy_r, en)\n",
    "\n",
    "\n",
    "\n",
    "logenergy = np.log10(energy_s)\n",
    "logpress = np.log10(pressure_s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $c_s^2$ and $\\gamma$ (if the derivative is correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/3095101516.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  cs2 = dpdr/dedr + dpdt/dedt + dpdy/dedy\n",
      "/tmp/ipykernel_233/3095101516.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  cs2 = dpdr/dedr + dpdt/dedt + dpdy/dedy\n"
     ]
    }
   ],
   "source": [
    "e = m_n * data['eos.nb'][index_nb] * ( 1 + data['eos.thermo'][:, 9] + energy_shift)\n",
    "e_r = e[maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :]) ]\n",
    "\n",
    "dpdr = np.zeros_like(e_r)\n",
    "dedr = np.zeros_like(e_r)\n",
    "for i in range(pointsyq):\n",
    "    for j in range(pointstemp):\n",
    "        for k in range(pointsrho-1):\n",
    "            h = (data['eos.nb'][k+1] - data['eos.nb'][k])*m_n\n",
    "            dpdr[i, j, k] = (pressure_s[i, j, k+1] - pressure_s[i, j, k]) / ( h )\n",
    "            dedr[i, j, k] = (e_r[i, j, k+1] - e_r[i, j, k]) / ( h )\n",
    "\n",
    "dpdt = np.zeros_like(e_r)\n",
    "dedt = np.zeros_like(e_r)\n",
    "for i in range(pointsyq):\n",
    "    for j in range(pointsrho):\n",
    "        for k in range(pointstemp-1):\n",
    "            h = data['eos.t'][k+1] - data['eos.t'][k]\n",
    "            dpdt[i, k, j] = (pressure_s[i, k+1, j] - pressure_s[i, k, j]) / ( h )\n",
    "            dedt[i, k, j] = (e_r[i, k+1, j] - e_r[i, k, j]) / ( h )\n",
    "\n",
    "dpdy = np.zeros_like(e_r)\n",
    "dedy = np.zeros_like(e_r)\n",
    "for i in range(pointstemp):\n",
    "    for j in range(pointsrho):\n",
    "        for k in range(pointsyq-1):\n",
    "            h = data['eos.yq'][k+1] - data['eos.yq'][k]\n",
    "            dpdy[k, i, j] = (pressure_s[k+1, i, j] - pressure_s[k, i, j]) / ( h )\n",
    "            dedy[k, i, j] = (e_r[k+1, i, j] - e_r[k, i, j]) / ( h )\n",
    "\n",
    "cs2 = dpdr/dedr + dpdt/dedt + dpdy/dedy\n",
    "gamma = e_r * cs2 / pressure_r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass fractions $X_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_index = {\n",
    "    0    : 'e',\n",
    "    10   : 'n',\n",
    "    11   : 'p',\n",
    "    100  : 'Λ',\n",
    "    110  : 'Σ−',\n",
    "    111  : 'Σ0',\n",
    "    112  : 'Σ+',\n",
    "    120  : 'Ξ−',\n",
    "    121  : 'Ξ0',\n",
    "    4002 : '24He',\n",
    "    3002 : '23He',\n",
    "    3001 : '13H',\n",
    "    2001 : '12H', \n",
    "    999  : 'other'\n",
    "}\n",
    "particle_index_inv = {v: k for k,v in particle_index.items()}\n",
    "\n",
    "baryonic_number = {\n",
    "    0  : 0,\n",
    "    10 : 1,\n",
    "    11 : 1,\n",
    "    100 : 1,\n",
    "    110 : 1,\n",
    "    111 : 1,\n",
    "    112 : 1,\n",
    "    120 : 1,\n",
    "    121 : 1,\n",
    "    4002 : 4,\n",
    "    3002 : 3,\n",
    "    3001 : 3,\n",
    "    2001 : 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_fractions = {}\n",
    "for i, row in enumerate(data['eos.compo']):\n",
    "    n_pairs = int(row[4])\n",
    "    n_quads = int(row[5 + n_pairs * 2])\n",
    "    \n",
    "    for j in range(5, 5 + n_pairs * 2, 2):\n",
    "        particle = int(row[j])\n",
    "        try:\n",
    "            mass_fractions[f'X{particle_index[particle]}'][i] = row[j+1] * baryonic_number[particle]\n",
    "        except KeyError:\n",
    "            mass_fractions[f'X{particle_index[particle]}'] = np.full(len(data['eos.compo']), np.NaN)\n",
    "            mass_fractions[f'X{particle_index[particle]}'][i] = row[j+1] * baryonic_number[particle]\n",
    "    \n",
    "    if n_quads > 0:\n",
    "        for j in range(5 + n_pairs * 2 + 1, 5 + n_pairs * 2 + n_quads * 4, 4):\n",
    "            particle = int(row[j])\n",
    "            try:\n",
    "                mass_fractions[f'X{particle_index[particle]}'][i] = row[j+1] * row[j+3]\n",
    "            except KeyError:\n",
    "                mass_fractions[f'X{particle_index[particle]}'] = np.full(len(data['eos.compo']), np.NaN)\n",
    "                mass_fractions[f'X{particle_index[particle]}'][i] = row[j+1] * row[j+3]\n",
    "for key in mass_fractions.keys():\n",
    "    mass_fractions[key] = mass_fractions[key][maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_fractions_2 = {}\n",
    "for i, row in enumerate(data['eos.compo']):\n",
    "    # Extract the number of pairs and quads from the current row\n",
    "    n_pairs_2 = int(row[4])\n",
    "    n_quads_2 = int(row[5 + n_pairs_2 * 2])\n",
    "\n",
    "    conc_iter = chain(range(5, 5 + n_pairs_2 * 2, 2), range(5 + n_pairs_2 * 2 + 1, 5 + n_pairs_2 * 2 + 1 + n_quads_2 * 4, 4))\n",
    "    # Iterate through the pairs and quads\n",
    "    for j in conc_iter:\n",
    "        # Get the particle_2\n",
    "        particle_2 = int(row[j])\n",
    "        # If j is within the range of the pairs, get its mass fraction\n",
    "        if j < 5 + n_pairs_2 * 2:\n",
    "            mass_fraction_2 = row[j+1] * baryonic_number[particle_2]\n",
    "        # If j is within the range of the quads, get its mass fraction\n",
    "        else:\n",
    "            mass_fraction_2 = row[j+1] * row[j+3]\n",
    "        \n",
    "        # Try to add the mass fraction to the mass_fractions_2 dictionary\n",
    "        # If the particle_2 is not already in the dictionary, create a new entry\n",
    "        # with a default value of NaN for all indices\n",
    "        try:\n",
    "            mass_fractions_2[f'X{particle_index[particle_2]}'][i] = mass_fraction_2\n",
    "        except KeyError:\n",
    "            mass_fractions_2[f'X{particle_index[particle_2]}'] = np.full(len(data['eos.compo']), np.NaN)\n",
    "            mass_fractions_2[f'X{particle_index[particle_2]}'][i] = mass_fraction_2\n",
    "\n",
    "for key in mass_fractions_2.keys():\n",
    "    mass_fractions_2[key] = mass_fractions_2[key][maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(compare_approximate(mass_fractions, mass_fractions_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/3138554122.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mus[f'mu_{particle_index[key]}'][k, i, j] = baryonic_number[key] * ( free_energy[k+1, i, j] - free_energy[k, i, j] ) / (mass_fractions[f'X{particle_index[key]}'][k+1, i, j] - mass_fractions[f'X{particle_index[key]}'][k, i, j] ) / data['eos.nb'][j]\n",
      "/tmp/ipykernel_233/3138554122.py:14: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  mus[f'mu_{particle_index[key]}'][k, i, j] = baryonic_number[key] * ( free_energy[k+1, i, j] - free_energy[k, i, j] ) / (mass_fractions[f'X{particle_index[key]}'][k+1, i, j] - mass_fractions[f'X{particle_index[key]}'][k, i, j] ) / data['eos.nb'][j]\n",
      "/tmp/ipykernel_233/3138554122.py:14: RuntimeWarning: overflow encountered in double_scalars\n",
      "  mus[f'mu_{particle_index[key]}'][k, i, j] = baryonic_number[key] * ( free_energy[k+1, i, j] - free_energy[k, i, j] ) / (mass_fractions[f'X{particle_index[key]}'][k+1, i, j] - mass_fractions[f'X{particle_index[key]}'][k, i, j] ) / data['eos.nb'][j]\n"
     ]
    }
   ],
   "source": [
    "mus = {}\n",
    "free_energy = data['eos.thermo'][:, 9]\n",
    "free_energy = free_energy[maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :]) ]\n",
    "\n",
    "for key in particle_index.keys():\n",
    "    if key == 999:\n",
    "        continue\n",
    "\n",
    "    mus[f'mu_{particle_index[key]}'] = np.full(len(data['eos.compo']), np.NaN)[maps(np.arange(pointsyq)[:, None, None], np.arange(pointstemp)[None, :, None], np.arange(pointsrho)[None, None, :]) ]\n",
    "\n",
    "    for i in range(pointstemp):\n",
    "        for j in range(pointsrho):\n",
    "            for k in range(pointsyq-1):\n",
    "                mus[f'mu_{particle_index[key]}'][k, i, j] = baryonic_number[key] * ( free_energy[k+1, i, j] - free_energy[k, i, j] ) / (mass_fractions[f'X{particle_index[key]}'][k+1, i, j] - mass_fractions[f'X{particle_index[key]}'][k, i, j] ) / data['eos.nb'][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mu_e', 'mu_n', 'mu_p', 'mu_Λ', 'mu_Σ−', 'mu_Σ0', 'mu_Σ+', 'mu_Ξ−', 'mu_Ξ0', 'mu_24He', 'mu_23He', 'mu_13H', 'mu_12H'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutto insieme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/1322980972.py:5: RuntimeWarning: invalid value encountered in log10\n",
      "  'logpress_shifted' : logpress , 'pressure_shift': pressure_shift, 'logpress' : np.log10(pressure_r),\n"
     ]
    }
   ],
   "source": [
    "ds = {  \n",
    "        'logrho'   : logrho   , 'pointsrho'     : pointsrho, \n",
    "        'y_q'      : y_q      , 'pointsyq'      : pointsyq, \n",
    "        'logtemp'  : logtemp  , 'pointstemp'    : pointstemp, \n",
    "        'logpress_shifted' : logpress , 'pressure_shift': pressure_shift, 'logpress' : np.log10(pressure_r),\n",
    "        'entropy'  : entropy_r, \n",
    "        'logenergy': logenergy, 'energy_shift'  : energy_shift,\n",
    "        'cs2'      : cs2      , 'gamma'         : gamma\n",
    "    }\n",
    "\n",
    "for key in mass_fractions_2.keys():\n",
    "    ds[key] = mass_fractions_2[key]\n",
    "for key in mus.keys():\n",
    "    ds[key] = mus[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: Syntax error: \"(\" unexpected\n"
     ]
    }
   ],
   "source": [
    "os.system(f'rm {OUTPUT}')\n",
    "\n",
    "with h5py.File(OUTPUT, \"w\") as f:\n",
    "    for d in ds:\n",
    "        dset = f.create_dataset(d, data=ds[d], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e93ca5520f225d1ab3b5a16366e62be7f564143f885fceba6e129ad9630726fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
